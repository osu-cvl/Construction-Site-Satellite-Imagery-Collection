{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial for Gathering Construction Sites\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was developed by  \n",
    "\n",
    "    Nicholas Kashani Motlagh, Aswathnarayan Radhakrishnan, Jim Davis @ Ohio State University  \n",
    "    {kashanimotlagh.1,radhakrishnan.39,davis.1719}@osu.edu  \n",
    "    \n",
    "    and  \n",
    "    \n",
    "    Roman Ilin @ AFRL/RYAP, Wright-Patterson AFB  \n",
    "    rilin325@gmail.com  \n",
    "\n",
    "Should you have any questions, the principal point-of-contact is Dr. Jim Davis. This package was modified on 2020-08-05."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "Make sure you have completed the prerequisites in [README.md](./README.md) before continuing this demo. This demo assumes some basic knowledge of jupyter lab and OpenStreetMap. Here is more information on [jupyter lab](https://jupyterlab.readthedocs.io/en/stable/) and [OpenStreetMap](https://wiki.openstreetmap.org/wiki/Beginners_Guide_1.3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acquiring History Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script relies on OpenStreetMap history files. History files are used to observe construction changes over time. To download a history file, you will need an OpenStreetMap account.\n",
    "This is free and quick to do. Simply navigate to this [link](https://www.openstreetmap.org/user/new). Once you have made an account, you can now access the internal history files. For this demo, we will be extracting construction sites in Ohio, specifically inside The Ohio State University campus.\n",
    "* Navigate to this [link](http://download.geofabrik.de/north-america/us/ohio.html).\n",
    "* Scroll to \"Other Formats and Auxillary Files\" and click the link \"internal server\".\n",
    "* Click \"Login with your OpenStreetMap account\" and enter your credentials.  \n",
    "\n",
    "After you are logged in, you will be able to download the previously crossed-out internal.osh.pbf file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find other history files [here](http://download.geofabrik.de). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Poly Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script needs a poly file which defines the bounds of the search. The poly file must be contained in the region that was downloaded. For more information on poly files, navigate to this [link](https://wiki.openstreetmap.org/wiki/Osmosis/Polygon_Filter_File_Format). For convenience, some example poly files can be found in `poly/`. Additionally, you can download the poly file of a region [here](http://download.geofabrik.de) under \"Other Formats and Auxillary Files\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Site Extraction\n",
    "In order to gather imagery of OpenStreetMap construction sites, we must first create a GeoDataFrame using the following modules. `setup` will be used to setup the necessary directories. Then, `extract_sites` will be used to create a GeoDataFrame of construction sites from an OpenStreetMap history file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "The directory structure required for the extract_sites module is below.\n",
    "```\n",
    "temp/\n",
    "    snapshots/\n",
    "    \n",
    "output/\n",
    "   collection/\n",
    "```\n",
    "\n",
    "Run the following cell to setup the directory structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from setup import setup_directory\n",
    "setup_directory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reset Directories\n",
    "You can clear the directories you just setup at any time by running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import reset_extract\n",
    "reset_extract.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining GeoDataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module will record all construction sites that were under construction in between the\n",
    "start and end window given in the arguments and save the file as a GeoDataFrame found in `output/collection/collection.shp`. If a construction site began or ended outside the window, but it was under construction inside the window, it will appear in the GeoDataFrame with correct start and end dates.  \n",
    "\n",
    "The GeoDataFrame will contain a row for each construction site observed. Each row has a unique \"chain_id\" identifier followed by a start date, end date, construction type, previous tag, final tag, and polygon coordinates which define a bounding box containing the construction shape.  \n",
    "\n",
    "We will use the extract_sites module to get a GeoDataFrame of construction sites over time in a specified polygon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import extract_sites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To gather construction sites, we need to define input parameters to the script. This script will accept start dates after 2015-06-23."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters for site extraction:  \n",
    "`start`: Get construction sites which were under construction on or after this date (YYYY-MM-DD). This date must be on or after 2015-06-23.  \n",
    "`end`: Get construction sites which were under construction before or on this date (YYYY-MM-DD). This date must be on or before 10 days from today.  \n",
    "`poly`: The path to the poly file to search for construction sites.  \n",
    "`region`: The path to the history file containing the polygon from the poly file.  \n",
    "`keep-temp`: If set to true, the temp directory will not be deleted. (Default: False)  \n",
    "`restrict-window`: If set to true, construction sites within the window will be located. In this case, `output/collection/collection.shp` will contain sites that end in the window. (Default: False)  \n",
    "`save-wip`: If set to true, a work-in-progress GeoDataFrame will be saved as `output/collection/in_progress.shp`. (Default: False)   \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify the parameters below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start date of the search in isoformat\n",
    "start_date = '2018-04-15'\n",
    "# end date of the search in isoformat\n",
    "end_date = '2020-07-01'\n",
    "# location of the polygon of osu campus which we will be analyzing\n",
    "poly_file = \"poly/campus.poly\"\n",
    "# location of the history file contianing osu campus\n",
    "region_file = \"\"\n",
    "# set to false if temp directory should be deleted\n",
    "keep_temp_files = False\n",
    "# set to true if you would only like to search within the window\n",
    "restrict_window = False\n",
    "# set to true if you would like to save the dataframe containing work-in-progress sites\n",
    "save_wip = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will assign the parameters of the extract sites module to the parameters entered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"start\": start_date, \"end\":end_date, \"poly\":poly_file, \"region\":region_file,\n",
    "          \"keep-temp\": keep_temp_files, \"restrict-window\":restrict_window, \"save-wip\":save_wip}\n",
    "extract_sites.set_params(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the parameters are assigned, we can extract the polygon from the region file we've provided and locate construction sites. The time this function takes depends on the region size and length of construction timelines. This function will return two compiled data frames of all construction sites: the first contains sites that are still under construction, and the second contains completed sites. This function also saves completed sites to `output/collection/collection.shp` and optionally saves the sites in-progress to `output/collection/in_progress.shp` if `save-wip = True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "in_progress_gdf, collection_gdf = extract_sites.locate_construction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also plot the GeoDataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_gdf.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a dataframe containing complete sites, lets create info text files for each site. This will make it easier to construct labeled datasets in the future. Info files are found in `output/{chain_id}/info.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_sites.create_dataset(collection_gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look at the distribution of our final tags in a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "histogram = {}\n",
    "for i,row in collection_gdf.iterrows():\n",
    "    if row[\"final_tag\"] not in histogram.keys():\n",
    "        histogram[row[\"final_tag\"]] = 1\n",
    "    else:\n",
    "        histogram[row[\"final_tag\"]] += 1\n",
    "plt.xticks(rotation=90)\n",
    "plt.bar(histogram.keys(), histogram.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Image Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a GeoDataFrame containing construction sites, we are ready to get imagery. We will use the gather_images module to download imagery over the course of construction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gather_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reset\n",
    "In order to clean all directories that have been made, run the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import reset_images\n",
    "reset_images.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "First, we will need to create directories for images to be stored. Here, we can set parameters for what source we want to use, what types of images to gather, how many images, and how much padding we want around the images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Planet\n",
    "Planet imagery is gathered in 2 steps: ordering and downloading.\n",
    "* An order is placed for every site after 2017-02-19 (no images will be gathered for a site that began before that date).\n",
    "* Planet imagery is sparse in 2017, but improves in more recent history.\n",
    "* You can download an order some time after it is created.\n",
    "* Each order can take between 5-15 minutes to download depending on the duration of construction.\n",
    "* You can set the email parameter to true to recieve an email every time an order is ready."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Sentinel\n",
    "Sentinel imagery is gathered in one step. Imagery is gathered for every site after 2015-06-23 (no images will be gathered for a site that began before that date).  \n",
    "\n",
    "In order to access imagery on sentinel hub, you must first create a new configuration on the sentinel dashboard found [here](https://apps.sentinel-hub.com/dashboard/#/configurations).\n",
    "\n",
    "<details>  \n",
    "<summary>Sentinel dashboard instructions</summary>\n",
    "    \n",
    "+ Click \"New configuration\"\n",
    "+ Enter in a name\n",
    "+ Select \"Python scripts template\" from the dropdown\n",
    "+ Edit your configuration\n",
    "+ Increase image quality to 100\n",
    "+ Click \"Add a new layer\"\n",
    "+ Name the new layer \"NIR\"\n",
    "+ Select \"B08\"\n",
    "+ Select \"B08 - reflectance\"\n",
    "+ Click \"Copy script to editor\"\n",
    "+ Click \"Set custom script\"\n",
    "+ Adjust the cloud coverage to 100\n",
    "+ Click \"Save\"\n",
    "\n",
    "**Creating a new layer whose \"ID\" is \"NIR\" is vital here.** Parameters such as cloud coverage and atmospheric correction can be changed; however, we will leave these as is for the sake of this demo.\n",
    "</details>  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters for image gathering  \n",
    "`rgb`: Downloads RGB images if set to True. (Default: False)  \n",
    "`nir`: Downloads NIR Images if set to True. (Default: False)  \n",
    "`source`: \"p\" downloads planet images; \"s\" downloads sentinel images.  \n",
    "`api`: the API Key for the source that you are using.  \n",
    "`download-planet`: download previouosly created planet orders. (Default: False)  \n",
    "`num-images`: The number of images to download including the start date and end date (evenly spaced). Set num-images >= 3 or -1 for all available imagery. (Default: 3)  \n",
    "`padding`: The scale factor to increase the bounding box area, center invariant. The bounding box will be scaled by sqrt(padding) in lat and long. (Default: 1)  \n",
    "`verbose`: Print script updates to console. (Default: False)  \n",
    "`email`: Receive email notifications for each complete order. (Default: False)  \n",
    "\n",
    "Modify the parameters below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to true to download RGB\n",
    "rgb = True\n",
    "# Set to true to download NIR\n",
    "nir = True \n",
    "# Set to p to download Planet, s to download Sentinel\n",
    "source = \"p\"\n",
    "# Set number of images to download\n",
    "num_images = 3\n",
    "# Set the padding scale factor\n",
    "padding = 1\n",
    "# Set to true to receive status updates\n",
    "verbose = True\n",
    "# Set to true to receive email notifications\n",
    "email = True\n",
    "# Set to true to download planets\n",
    "download_planet = False\n",
    "# Set to source API key (Sentinel instance id or Planet api key).\n",
    "api = \"\"\n",
    "\n",
    "params =  {\"rgb\": rgb, \"nir\": nir, \"source\": source, \"num-images\": num_images, \n",
    "           \"padding\": padding, \"verbose\": verbose, \"email\": email, \n",
    "           \"download-planet\": download_planet, \"api\": api}\n",
    "gather_images.set_params(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have to setup necessary directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the necessary directories\n",
    "gather_images.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Imagery\n",
    "Now our directories are setup and we are ready to gather images.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For platform independent paths\n",
    "from pathlib import Path\n",
    "# Used to read in the GeoDataFrame\n",
    "import geopandas as gpd\n",
    "# Read in the GeoDataFrame\n",
    "collection_gdf = gpd.read_file(str(Path(\"output/collection/collection.shp\")))\n",
    "# Start the retrieval process for source\n",
    "gather_images.gather_from_source(collection_gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using planet as a source, you will have to download images when orders are ready. Reassign parameters with `download-planet` set to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the mode to download\n",
    "params[\"download-planet\"] = True\n",
    "# Set the new parameters\n",
    "gather_images.set_params(params)\n",
    "# Download planet images\n",
    "gather_images.gather_from_source(collection_gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After images are downloaded, you can find them in `output/{chain_id}/images/{source}/{rgb_nir}`. Each image is labeled with the date it was captured."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
